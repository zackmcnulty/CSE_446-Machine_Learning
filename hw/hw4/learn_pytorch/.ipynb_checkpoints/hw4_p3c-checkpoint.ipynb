{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# LOADS CIFAR10 images which are 32 x 32 x 3 RGB images\n",
    "# iter(trainloader/testloader) are iterables that come in pairs (image, label)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 12 # number of epochs to train for\n",
    "momentum = 0.9 # momentum for Stochastic Gradient Descent\n",
    "lr = 0.001 # learning rate (eta) for gradient descent\n",
    "M = 100  # number of neurons in hidden layer of neural network\n",
    "p = 5  # filter window size \n",
    "N = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# NO PADDING\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, M, N, p):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # The 3 input channels are the RGB of the image\n",
    "        # the Kernel size is the size of the filter window (p x p in this case)\n",
    "        self.conv = nn.Conv2d(in_channels=3, out_channels=M, kernel_size=p, bias=True, padding=0)\n",
    "        \n",
    "        # Max pooling layer. kernel_size is the size of the window that is used. Max is selected within a N x N window\n",
    "        self.pool = nn.MaxPool2d(kernel_size=N)\n",
    "        \n",
    "        self.linear = nn.Linear(((33-p) // N)**2 * M,  10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # vectorize the data before feeding it into the linear layer. Note the 4 is due to the batch of size 4 used\n",
    "        # (see homework specification)\n",
    "        x = x.view(4, -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "net = Net(M, N, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define a Loss function and optimizer\n",
    "\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train the network\n",
    "\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.952\n",
      "[1,  4000] loss: 1.706\n",
      "[1,  6000] loss: 1.566\n",
      "[1,  8000] loss: 1.490\n",
      "[1, 10000] loss: 1.450\n",
      "[1, 12000] loss: 1.408\n",
      "END OF EPOCH  1 : train accuracy =  52.632  // test accuracy =  51.95\n",
      "[2,  2000] loss: 1.337\n",
      "[2,  4000] loss: 1.324\n",
      "[2,  6000] loss: 1.292\n",
      "[2,  8000] loss: 1.292\n",
      "[2, 10000] loss: 1.281\n",
      "[2, 12000] loss: 1.237\n",
      "END OF EPOCH  2 : train accuracy =  58.058  // test accuracy =  56.74\n",
      "[3,  2000] loss: 1.219\n",
      "[3,  4000] loss: 1.212\n",
      "[3,  6000] loss: 1.204\n",
      "[3,  8000] loss: 1.235\n",
      "[3, 10000] loss: 1.185\n",
      "[3, 12000] loss: 1.198\n",
      "END OF EPOCH  3 : train accuracy =  61.292  // test accuracy =  59.87\n",
      "[4,  2000] loss: 1.166\n",
      "[4,  4000] loss: 1.187\n",
      "[4,  6000] loss: 1.165\n",
      "[4,  8000] loss: 1.136\n",
      "[4, 10000] loss: 1.154\n",
      "[4, 12000] loss: 1.150\n",
      "END OF EPOCH  4 : train accuracy =  61.486  // test accuracy =  59.0\n",
      "[5,  2000] loss: 1.119\n",
      "[5,  4000] loss: 1.122\n",
      "[5,  6000] loss: 1.130\n",
      "[5,  8000] loss: 1.142\n",
      "[5, 10000] loss: 1.125\n",
      "[5, 12000] loss: 1.109\n",
      "END OF EPOCH  5 : train accuracy =  63.018  // test accuracy =  60.55\n",
      "[6,  2000] loss: 1.110\n",
      "[6,  4000] loss: 1.088\n",
      "[6,  6000] loss: 1.084\n",
      "[6,  8000] loss: 1.106\n",
      "[6, 10000] loss: 1.097\n",
      "[6, 12000] loss: 1.125\n",
      "END OF EPOCH  6 : train accuracy =  63.04  // test accuracy =  60.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-76abd89550d5>\", line 16, in <module>\n",
      "    loss.backward()\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/site-packages/torch/tensor.py\", line 107, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 93, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/Users/zackmcnulty/anaconda3/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "all_train_accuracies = []\n",
    "all_test_accuracies = []\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    train_accuracy = calc_accuracy(trainloader)\n",
    "    test_accuracy = calc_accuracy(testloader)\n",
    "    print('END OF EPOCH ', epoch + 1, ': train accuracy = ', train_accuracy, ' // test accuracy = ', test_accuracy)\n",
    "    \n",
    "    all_train_accuracies.append(train_accuracy)\n",
    "    all_test_accuracies.append(test_accuracy)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot accuracy over time\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(all_train_accuracies)\n",
    "plt.plot(all_test_accuracies)\n",
    "plt.title('Training and Testing Accuracy after each iteration')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(['Training', 'Testing'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
